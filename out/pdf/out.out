\BOOKMARK [0][]{Cover.0}{Cover}{}% 1
\BOOKMARK [0][]{CoverGerman.0}{CoverGerman}{}% 2
\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 3
\BOOKMARK [0][]{chapter.2}{2 Related Work}{}% 4
\BOOKMARK [1][]{section*.5}{2.1 Parallel Haskells}{chapter.2}% 5
\BOOKMARK [1][]{section*.6}{2.2 Algorithmic skeletons}{chapter.2}% 6
\BOOKMARK [1][]{section*.7}{2.3 Arrows}{chapter.2}% 7
\BOOKMARK [1][]{section*.8}{2.4 Earlier work}{chapter.2}% 8
\BOOKMARK [0][]{chapter.3}{3 Background}{}% 9
\BOOKMARK [1][]{section*.10}{3.1 Functional programming}{chapter.3}% 10
\BOOKMARK [2][]{section*.11}{3.1.1 Why functional programming matters}{section*.10}% 11
\BOOKMARK [2][]{section*.12}{3.1.2 A short introduction to Haskell}{section*.10}% 12
\BOOKMARK [2][]{section*.15}{3.1.3 Monads}{section*.10}% 13
\BOOKMARK [2][]{section*.16}{3.1.4 Arrows}{section*.10}% 14
\BOOKMARK [1][]{section*.22}{3.2 Introduction to parallel Haskells}{chapter.3}% 15
\BOOKMARK [2][]{section*.24}{3.2.1 Glasgow parallel Haskell \205 GpH}{section*.22}% 16
\BOOKMARK [2][]{section*.26}{3.2.2 \040Monad}{section*.22}% 17
\BOOKMARK [2][]{section*.28}{3.2.3 Eden}{section*.22}% 18
\BOOKMARK [0][]{chapter.4}{4 Parallel Arrows}{}% 19
\BOOKMARK [1][]{section*.30}{4.1 The type class}{chapter.4}% 20
\BOOKMARK [1][]{section*.31}{4.2 \040instances}{chapter.4}% 21
\BOOKMARK [2][]{section*.32}{4.2.1 Glasgow parallel Haskell}{section*.31}% 22
\BOOKMARK [2][]{section*.34}{4.2.2 \040Monad}{section*.31}% 23
\BOOKMARK [2][]{section*.36}{4.2.3 Eden}{section*.31}% 24
\BOOKMARK [2][]{section*.38}{4.2.4 Default configuration instances}{section*.31}% 25
\BOOKMARK [1][]{section*.39}{4.3 Extending the interface}{chapter.4}% 26
\BOOKMARK [2][]{section*.40}{4.3.1 Lazy }{section*.39}% 27
\BOOKMARK [2][]{section*.43}{4.3.2 Heterogeneous tasks}{section*.39}% 28
\BOOKMARK [1][]{section*.46}{4.4 Basic -based skeletons}{chapter.4}% 29
\BOOKMARK [2][]{section*.47}{4.4.1 Parallel and laziness}{section*.46}% 30
\BOOKMARK [2][]{section*.52}{4.4.2 Statically load-balancing parallel }{section*.46}% 31
\BOOKMARK [0][]{chapter.5}{5 Further development of Parallel Arrows}{}% 32
\BOOKMARK [1][]{section*.58}{5.1 Futures}{chapter.5}% 33
\BOOKMARK [1][]{section*.61}{5.2 Advanced topological skeletons}{chapter.5}% 34
\BOOKMARK [2][]{section*.62}{5.2.1 Parallel pipe}{section*.61}% 35
\BOOKMARK [2][]{section*.66}{5.2.2 Ring skeleton}{section*.61}% 36
\BOOKMARK [2][]{section*.69}{5.2.3 Torus skeleton}{section*.61}% 37
\BOOKMARK [0][]{chapter.6}{6 Experiment: Cloud Haskell Backend}{}% 38
\BOOKMARK [1][]{section*.76}{6.1 Node discovery and program harness}{chapter.6}% 39
\BOOKMARK [2][]{section*.77}{6.1.1 The data-structure}{section*.76}% 40
\BOOKMARK [2][]{section*.78}{6.1.2 Starting slave nodes}{section*.76}% 41
\BOOKMARK [2][]{section*.79}{6.1.3 Starting master nodes}{section*.76}% 42
\BOOKMARK [2][]{section*.80}{6.1.4 Startup harness}{section*.76}% 43
\BOOKMARK [1][]{section*.81}{6.2 Parallel evaluation with Cloud Haskell}{chapter.6}% 44
\BOOKMARK [2][]{section*.82}{6.2.1 Communication basics}{section*.81}% 45
\BOOKMARK [2][]{section*.84}{6.2.2 Evaluation of values on slave nodes}{section*.81}% 46
\BOOKMARK [2][]{section*.85}{6.2.3 Parallel evaluation scheme}{section*.81}% 47
\BOOKMARK [1][]{section*.86}{6.3 Implementing the PArrows API}{chapter.6}% 48
\BOOKMARK [2][]{section*.87}{6.3.1 \040instance}{section*.86}% 49
\BOOKMARK [2][]{section*.88}{6.3.2 Limits of the current implementation}{section*.86}% 50
\BOOKMARK [2][]{section*.89}{6.3.3 Possible mitigation of the limits}{section*.86}% 51
\BOOKMARK [0][]{chapter.7}{7 Experimental performance results}{}% 52
\BOOKMARK [1][]{section*.91}{7.1 Measurement platform}{chapter.7}% 53
\BOOKMARK [2][]{section*.92}{7.1.1 Hardware and software}{section*.91}% 54
\BOOKMARK [2][]{section*.93}{7.1.2 Benchmarks}{section*.91}% 55
\BOOKMARK [2][]{section*.94}{7.1.3 Which parallel Haskells run where}{section*.91}% 56
\BOOKMARK [2][]{section*.95}{7.1.4 Effect of hyper-threading}{section*.91}% 57
\BOOKMARK [1][]{section*.96}{7.2 Benchmark results}{chapter.7}% 58
\BOOKMARK [2][]{section*.97}{7.2.1 Defining speedup}{section*.96}% 59
\BOOKMARK [2][]{section*.98}{7.2.2 Defining overhead}{section*.96}% 60
\BOOKMARK [2][]{section*.99}{7.2.3 Shared memory}{section*.96}% 61
\BOOKMARK [2][]{section*.100}{7.2.4 Distributed memory}{section*.96}% 62
\BOOKMARK [1][]{section*.102}{7.3 Evaluation of results}{chapter.7}% 63
\BOOKMARK [0][]{chapter.8}{8 Outlook}{}% 64
\BOOKMARK [1][]{section*.104}{8.1 Contributions}{chapter.8}% 65
\BOOKMARK [1][]{section*.105}{8.2 Evaluation of results}{chapter.8}% 66
\BOOKMARK [1][]{section*.106}{8.3 Conclusion}{chapter.8}% 67
\BOOKMARK [0][]{appendix.A}{A Appendix}{}% 68
\BOOKMARK [1][]{section*.108}{A.1 Profunctor Arrows}{appendix.A}% 69
\BOOKMARK [1][]{section*.110}{A.2 Additional function definitions}{appendix.A}% 70
\BOOKMARK [1][]{section*.116}{A.3 Syntactic sugar}{appendix.A}% 71
\BOOKMARK [1][]{section*.117}{A.4 Experimental Cloud Haskell backend code}{appendix.A}% 72
\BOOKMARK [1][]{section*.120}{A.5 Plots for the shared memory benchmarks}{appendix.A}% 73
\BOOKMARK [1][]{section*.135}{A.6 Plots for the distributed memory benchmarks}{appendix.A}% 74
\BOOKMARK [0][]{section*.143}{References}{}% 75
\BOOKMARK [0][]{Declaration.0}{Declaration}{}% 76
\BOOKMARK [0][]{section*.145}{List of Figures}{}% 77
\BOOKMARK [0][]{section*.145}{List of Tables}{}% 78
